{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "1 - SVM Data Prefiltering.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavinciB/child_grooming_detector/blob/main/src/SVM/1%20-%20SVM%20Data%20Prefiltering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mC1iDS4UruT",
        "outputId": "c4baecc5-8cf2-48af-9caa-b955e9641438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzJRSXMpCxtE"
      },
      "source": [
        "\"\"\"SVM Data Prefiltering\n",
        "\n",
        "This series of notebook will be used for the SVM implementation for online \n",
        "grooming. We will re-implement the SVM suggested by Villatoro-Tello et al.\n",
        "in the paper \"A Two-step Approach for Effective Detection of Misbehaving\n",
        "Users in Chats\".\n",
        "Prefiltering Training Data\n",
        "\n",
        "First, we want to do the required pre-filtering of training data. Any\n",
        "conversation meeting any of the following criteria are removed:\n",
        "\n",
        "    conversations with only one participant\n",
        "    conversations with each user having 6 or less messages\n",
        "    conversations with long sequences of unrecognized characters\"\"\"\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import datetime\n",
        "\n",
        "\"\"\"train_data_path = \"../../data/pan12-sexual-predator-identification-training-corpus-2012-05-01/\"\n",
        "test_data_path = \"../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/\"\n",
        "\n",
        "training_xml = ET.parse(train_data_path + 'pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
        "root = training_xml.getroot()*/\"\"\"\n",
        "\n",
        "train_data_path = r\"/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-training-corpus-2012-05-01\"\n",
        "test_data_path = r\"/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21\"\n",
        "\n",
        "training_xml = ET.parse(train_data_path + '/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
        "root = training_xml.getroot()        \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MQSBEUgCxtP",
        "outputId": "db59d5ca-50b4-4e71-d794-07fe55192d7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"Now root stores the xml file in a nested list, let's remove conversations \n",
        "meeting the first criteria: conversations with only one participant\"\"\"\n",
        "conv_2_remove = []\n",
        "authors = []\n",
        "init_len = len(root)\n",
        "\n",
        "for conversation in root:\n",
        "    authors.clear()\n",
        "    \n",
        "# finding all unique authors in this conversation\n",
        "    for message in conversation:\n",
        "        author = message.find('author').text\n",
        "        if author not in authors:\n",
        "            authors.append(author)\n",
        "\n",
        "    if (len(authors)) <= 1 and conversation.get('id') not in conv_2_remove:\n",
        "        conv_2_remove.append(conversation.get('id'))\n",
        "\n",
        "print(\"{} out of {} conversations should be removed\".format(len(conv_2_remove), init_len))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12773 out of 66927 conversations should be removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VESbeXdeCxtY",
        "outputId": "f7e163d8-9ea6-4698-9654-fe97cf8d2953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"We have now removed 12773 conversations. Next we remove all conversations \n",
        "that meet the second criteria: conversations with each user having 5 or less\n",
        " messages\"\"\"\n",
        "for conversation in root:\n",
        "    if conversation.get('id') in conv_2_remove:\n",
        "        continue\n",
        "    authors = {}\n",
        "    for message in conversation:\n",
        "        author = message.find('author').text\n",
        "        if author in authors:\n",
        "            authors[author] = authors[author] + 1\n",
        "        else:\n",
        "            authors[author] = 1\n",
        "    remove = True\n",
        "    for author in authors:\n",
        "        if authors[author] > 5:\n",
        "            remove = False\n",
        "    if remove is True and conversation.get('id') not in conv_2_remove:\n",
        "        conv_2_remove.append(conversation.get('id'))\n",
        "\n",
        "print(\"{} out of {} conversations should be removed\".format(len(conv_2_remove), init_len))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51827 out of 66927 conversations should be removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9pPGWvSCxte",
        "outputId": "9634ca9b-b3dc-480c-f510-34e4062e95f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"We have now removed 51827 conversations out of the original 66927.\n",
        "Lastly we will remove any conversations with messages containing long\n",
        "sequences of unrecognized characters\"\"\"\n",
        "\n",
        "import re\n",
        "for conversation in root:\n",
        "    if conversation.get('id') in conv_2_remove:\n",
        "        continue\n",
        "    remove = False\n",
        "    for message in conversation:\n",
        "        text = message.find(\"text\").text\n",
        "        if text is None or len(text) < 20:\n",
        "            continue\n",
        "        match_str = re.findall(\"[\\W_]\", text)\n",
        "        if len(match_str) / len(text) > 0.6:\n",
        "            remove = True\n",
        "            break\n",
        "\n",
        "    if remove is True and conversation.get('id') not in conv_2_remove:\n",
        "            conv_2_remove.append(conversation.get('id'))\n",
        "\n",
        "print(\"{} out of {} conversations should be removed\".format(len(conv_2_remove), init_len))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52224 out of 66927 conversations should be removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIvPfFUBCxtj",
        "outputId": "06c883e0-4e23-4f71-df18-73eaf238a2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"We have now removed 52224 out of 66927 conversations.\n",
        "Next we remove the conversations we want to remove from root itself\n",
        "and write the new xml back into aother file.\"\"\"\n",
        "for conversation in root.findall('conversation'):\n",
        "    if conversation.get('id') in conv_2_remove:\n",
        "        root.remove(conversation)\n",
        "print(\"The new root has a length of {}.\".format(len(root)))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The new root has a length of 14703.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezeUIf2DCxtm",
        "outputId": "4428c727-dc7d-47de-e2a3-50770e051fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from xml.etree.ElementTree import ElementTree\n",
        "tree = ElementTree(root)\n",
        "tree.write(open(r'/content/drive/MyDrive/online-grooming-detector-master/data/svm_training_data/training_data.xml', 'wb'))\n",
        "print(\"Filtered data written!\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtered data written!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}